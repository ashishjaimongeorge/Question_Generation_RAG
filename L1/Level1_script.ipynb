{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVnMLJm99OHk"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from datetime import datetime\n",
        "import json\n",
        "import openai\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not OPENAI_API_KEY:\n",
        "    raise EnvironmentError(\"OpenAI API key is missing. Please set it in the .env file.\")\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extracts text from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of text segments, one for each page.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the PDF file does not exist.\n",
        "        ValueError: If the PDF file cannot be read.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "        raise FileNotFoundError(f\"PDF file not found at path: {pdf_path}\")\n",
        "\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        text_segments = [page.extract_text() for page in reader.pages]\n",
        "        if not text_segments:\n",
        "            raise ValueError(\"PDF text extraction returned empty content.\")\n",
        "        return text_segments\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error extracting text from PDF: {e}\")\n",
        "\n",
        "def extract_keywords(text_segments):\n",
        "    \"\"\"\n",
        "    Extracts main keywords from the provided text using OpenAI.\n",
        "\n",
        "    Args:\n",
        "        text_segments (list): List of text segments.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of keywords.\n",
        "\n",
        "    Raises:\n",
        "        RuntimeError: If the OpenAI API call fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        joined_text = \" \".join(text_segments[:3])  # Using the first 3 pages\n",
        "        prompt = f\"Extract the main keywords from the following text:\\n{joined_text}\\n\\nProvide the keywords as a comma-separated list.\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4-0613\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=500\n",
        "        )\n",
        "        keywords = response.choices[0].message['content'].split(\",\")\n",
        "        return [keyword.strip() for keyword in keywords if keyword.strip()]\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error extracting keywords using OpenAI: {e}\")\n",
        "\n",
        "def generate_question_from_keyword(keyword, context_text):\n",
        "    \"\"\"\n",
        "    Generates a multiple-choice question based on a keyword and context.\n",
        "\n",
        "    Args:\n",
        "        keyword (str): The keyword to base the question on.\n",
        "        context_text (str): Contextual text for generating the question.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the question, options, and the correct answer.\n",
        "\n",
        "    Raises:\n",
        "        RuntimeError: If the OpenAI API call fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        Based on the following keyword: \"{keyword}\" and the context: \"{context_text}\",\n",
        "        generate:\n",
        "        - One multiple-choice question\n",
        "        - Four options labeled A, B, C, and D\n",
        "        - The correct answer with its label (e.g., 'A', 'B', etc.)\n",
        "\n",
        "        Provide the output in this format:\n",
        "        {{\n",
        "            \"question\": \"<Question text>\",\n",
        "            \"options\": [\"A) <Option 1>\", \"B) <Option 2>\", \"C) <Option 3>\", \"D) <Option 4>\"],\n",
        "            \"correct_answer\": \"<Correct Option Label>\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4-0613\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=500\n",
        "        )\n",
        "        return json.loads(response.choices[0].message['content'])\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error generating question using OpenAI for keyword '{keyword}': {e}\")\n",
        "\n",
        "def format_output(keywords, questions):\n",
        "    \"\"\"\n",
        "    Formats the output data for keywords and questions into JSON-ready dictionaries.\n",
        "\n",
        "    Args:\n",
        "        keywords (list): List of extracted keywords.\n",
        "        questions (list): List of generated questions.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two dictionaries: topics_data and questions_data.\n",
        "    \"\"\"\n",
        "    topics_data = {\n",
        "        \"book_title\": \"Project Management Professional Guide\",\n",
        "        \"total_keywords\": len(keywords),\n",
        "        \"extraction_timestamp\": datetime.now().isoformat(),\n",
        "        \"keywords\": keywords\n",
        "    }\n",
        "\n",
        "    questions_data = {\n",
        "        \"metadata\": {\n",
        "            \"generated_at\": datetime.now().isoformat(),\n",
        "            \"total_questions\": len(questions),\n",
        "            \"book_title\": \"Project Management Professional Guide\",\n",
        "            \"tool_used\": \"GPT-4\"\n",
        "        },\n",
        "        \"questions\": questions\n",
        "    }\n",
        "    return topics_data, questions_data\n",
        "\n",
        "def save_to_json(data, filename):\n",
        "    \"\"\"\n",
        "    Saves data to a JSON file.\n",
        "\n",
        "    Args:\n",
        "        data (dict): Data to save.\n",
        "        filename (str): Path to the output JSON file.\n",
        "\n",
        "    Raises:\n",
        "        IOError: If the file cannot be written.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(data, f, indent=4)\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error saving data to JSON file '{filename}': {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        pdf_path = \"Project.pdf\"\n",
        "        text_segments = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "        print(\"Extracting keywords...\")\n",
        "        keywords = extract_keywords(text_segments)\n",
        "        print(f\"Keywords extracted: {keywords}\")\n",
        "\n",
        "        print(\"Generating questions...\")\n",
        "        questions = []\n",
        "        context = \" \".join(text_segments[:3])\n",
        "        for keyword in keywords:\n",
        "            question_data = generate_question_from_keyword(keyword, context)\n",
        "            question_data[\"topic\"] = keyword\n",
        "            questions.append(question_data)\n",
        "        print(f\"Generated {len(questions)} questions.\")\n",
        "\n",
        "        print(\"Formatting output...\")\n",
        "        topics_data, questions_data = format_output(keywords, questions)\n",
        "\n",
        "        print(\"Saving to JSON files...\")\n",
        "        save_to_json(topics_data, \"keywords.json\")\n",
        "        save_to_json(questions_data, \"questions.json\")\n",
        "\n",
        "        print(\"Keyword-based question generation completed and saved to JSON!\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    }
  ]
}