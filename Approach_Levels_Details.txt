
### Level 1: Approach Explanation

---

#### # Tools & Frameworks
- Used **PyPDF2** for extracting text from the PDF document.  
- Leveraged **OpenAI GPT-4** to generate embeddings and questions based on keywords.  

---

#### # Approach
1. **Text Extraction**:
   - Used `PyPDF2` to extract text with page numbers from the PDF file.  
   - Organized extracted data into a structured format, pairing text with corresponding page numbers.  

2. **Keyword Extraction**:
   - Used GPT-4 to identify keywords from the text.  
   - Keywords were limited to 10 for simplicity and relevance.  

3. **Question Generation**:
   - For each extracted keyword, GPT-4 generated a basic multiple-choice question.  
   - Questions included four options and a correct answer.

---

#### # Challenges & Solutions
1. **Challenge: PDF Formatting Issues**:
   - Some PDFs have inconsistent or non-parsed text structures.  
   **Solution**: Used `PyPDF2` to extract text, with error handling for cases where extraction fails.  

2. **Challenge: Limited Context for Questions**:
   - Using only keywords can lead to overly generic questions.  
   **Solution**: Supplemented keyword-based question generation with page-level context where possible.  

---

#### # Suggestions for L1 Improvement
1. Include text cleaning steps (e.g., removing unwanted characters, normalizing text).  
2. Expand keyword extraction to consider the entire document or specific sections.  
3. Add preliminary embeddings generation for better context representation.

---

### Level 2: Approach Explanation

---

#### # Tools & Frameworks
- Used **OpenAI GPT-4** for topic extraction and question generation.  
- Leveraged **Pinecone** as a vector database to index and retrieve text segments.  
- Used `text-embedding-ada-002` for generating embeddings.

---

#### # Approach
1. **Text Segmentation and Indexing**:
   - Split extracted text into segments paired with metadata (e.g., page numbers).  
   - Generated embeddings for each text segment using OpenAIâ€™s `text-embedding-ada-002` model.  
   - Stored these embeddings in Pinecone for efficient similarity search.

2. **Topic Extraction**:
   - Used GPT-4 to extract main topics by analyzing the first five pages of the document.  
   - Topics were structured as a numbered list to represent content at a higher granularity.  

3. **Context Retrieval**:
   - Queried Pinecone with topic embeddings to retrieve the top 5 relevant text segments for each topic.  
   - Each retrieved segment was ranked based on similarity scores.

4. **Question Generation**:
   - Generated multiple-choice questions using topics and their retrieved context chunks.  
   - Questions included options, correct answers, and basic context linkage.

---

#### # Challenges & Solutions
1. **Challenge: Chunking Strategy**:
   - Text segments were sometimes too large or too small, leading to loss of meaning.  
   **Solution**: Used page-based segmentation with overlap to ensure context continuity.  

2. **Challenge: Topic Relevance**:
   - Retrieved topics sometimes lacked precise relevance to the content.  
   **Solution**: Improved context embedding queries to refine topic-to-segment matching.  

3. **Challenge: Vector Management**:
   - Large PDFs resulted in extensive embeddings and index entries, increasing storage.  
   **Solution**: Limited indexed segments to relevant sections of the PDF.  

---

#### # Pinecone Usage
- Pinecone was used to:  
  - **Index**: Store embeddings of text segments with metadata (text, page number).  
  - **Query**: Retrieve the top 5 matching text segments for each topic using cosine similarity.

---

#### # Suggestions for L2 Improvement
1. Fine-tune chunking to balance segment size for better topic relevance.  
2. Use metadata tags (e.g., chapter headings) to enhance segment context during retrieval.  
3. Include a feedback loop to validate topic-to-context relevance dynamically.

---

### Level 3: Approach Explanation

---

#### # Tools & Frameworks
- Used **OpenAI fine-tuned GPT-4 model** for domain-specific question generation.  
- Continued using **Pinecone** for retrieving context and storing embeddings.  
- Leveraged `text-embedding-ada-002` for embedding generation.

---

#### # Approach
1. **Enhanced Context Retrieval**:
   - Queried Pinecone with finely tuned topic embeddings to retrieve context with the highest confidence scores.  
   - Retrieved chunks were ranked and filtered to ensure precision.

2. **Detailed Question Generation**:
   - Used the fine-tuned OpenAI GPT-4 model to generate 5 multiple-choice questions per topic.  
   - Each question included:
     - Four answer options (A, B, C, D).
     - Correct answer with explanation.
     - Confidence score for retrieval relevance.

3. **Robust JSON Formatting**:
   - Implemented JSON validation and cleanup to ensure output consistency.  
   - Added error handling for malformed responses from GPT-4.

---

#### # Challenges & Solutions
1. **Challenge: JSON Parsing Issues**:
   - GPT responses occasionally included formatting errors.  
   **Solution**: Added regular expression-based cleanup and fallback parsing strategies.  

2. **Challenge: Maintaining Question Quality**:
   - Questions required deeper context understanding and clarity.  
   **Solution**: Fine-tuned the OpenAI GPT-4 model on similar datasets for better output.  

3. **Challenge: High Query Costs**:
   - Frequent embedding generation and Pinecone queries increased costs.  
   **Solution**: Cached embeddings for previously queried topics to reduce redundant computations.

---

#### # Pinecone Usage
- **Enhanced Usage**:  
  - Stored both text embeddings and metadata.  
  - Retrieved and ranked relevant context chunks for each topic.  

---

#### # Suggestions for L3 Improvement
1. Integrate additional metadata (e.g., chapter headings, section titles) to improve query precision.  
2. Explore cost-optimization techniques (e.g., batch processing, caching) to minimize embedding and query expenses.  
3. Expand question formats to include open-ended and fill-in-the-blank types.  
4. **Handle Table-Like Structures**:  
   - The provided data includes table-like formats which are difficult to vectorize.  
   - Semantic relationships between rows and columns are not well captured by vector-based methods.  
   - **Proposed Solution**: Explore the use of a knowledge graph, representing data points as nodes and their relationships as edges.  
   - This approach would allow for better semantic understanding but requires additional exploration and implementation time.

---
