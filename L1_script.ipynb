{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVnMLJm99OHk"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from datetime import datetime\n",
        "import json\n",
        "import openai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Initialize Pinecone\n",
        "PINECONE_API_KEY = \"f96ec14c-1e9e-4975-8f79-dd0b7f7857ca\"\n",
        "pc = Pinecone(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    spec=ServerlessSpec(\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\"\n",
        "    )\n",
        ")\n",
        "index_name = \"jesus\"\n",
        "\n",
        "# Create Pinecone index if not exists\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# OpenAI API setup\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def extract_text_with_page_numbers(pdf_path):\n",
        "    \"\"\"Extract text from a PDF file with corresponding page numbers.\"\"\"\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        text_segments = []\n",
        "        for page_number, page in enumerate(reader.pages, start=1):\n",
        "            text_segments.append({\n",
        "                \"page_number\": page_number,\n",
        "                \"text\": page.extract_text()\n",
        "            })\n",
        "        return text_segments\n",
        "    except Exception as e:\n",
        "        print(f\"Error while reading PDF: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_keywords(text_segments, limit=10):\n",
        "    \"\"\"Extract keywords from the content and limit the result to a specified number.\"\"\"\n",
        "    try:\n",
        "        joined_text = \" \".join(segment[\"text\"] for segment in text_segments[:3])  # First few pages\n",
        "        prompt = f\"Extract the main keywords from the following text:\\n{joined_text}\\n\\nProvide the keywords as a comma-separated list.\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4-0613\",\n",
        "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                      {\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=500\n",
        "        )\n",
        "        keywords = response.choices[0].message['content'].split(\",\")\n",
        "        return [keyword.strip() for keyword in keywords if keyword.strip()][:limit]\n",
        "    except Exception as e:\n",
        "        print(f\"Error while extracting keywords: {e}\")\n",
        "        return []\n",
        "\n",
        "def generate_question_from_keyword(keyword, context_data):\n",
        "    \"\"\"Generate a question, options, and the correct answer for a given keyword, including page number.\"\"\"\n",
        "    try:\n",
        "        context_text = context_data[\"text\"]\n",
        "        page_number = context_data[\"page_number\"]\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Based on the following keyword: \"{keyword}\" and the context: \"{context_text}\",\n",
        "        generate:\n",
        "        - One multiple-choice question\n",
        "        - Four options labeled A, B, C, and D\n",
        "        - The correct answer with its label (e.g., 'A', 'B', etc.)\n",
        "\n",
        "        Provide the output in this format:\n",
        "        {{\n",
        "            \"question\": \"<Question text>\",\n",
        "            \"options\": [\"A) <Option 1>\", \"B) <Option 2>\", \"C) <Option 3>\", \"D) <Option 4>\"],\n",
        "            \"correct_answer\": \"<Correct Option Label>\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4-0613\",\n",
        "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                      {\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=500\n",
        "        )\n",
        "        question_data = json.loads(response.choices[0].message['content'])\n",
        "        question_data[\"page_number\"] = page_number  # Add the page number\n",
        "        return question_data\n",
        "    except Exception as e:\n",
        "        print(f\"Error while generating question for keyword '{keyword}': {e}\")\n",
        "        return {}\n",
        "\n",
        "def format_output(keywords, questions):\n",
        "    \"\"\"Format the keywords and questions into JSON format.\"\"\"\n",
        "    # Keywords JSON\n",
        "    topics_data = {\n",
        "        \"book_title\": \"Project Management Professional Guide\",\n",
        "        \"total_keywords\": len(keywords),\n",
        "        \"extraction_timestamp\": datetime.now().isoformat(),\n",
        "        \"keywords\": keywords\n",
        "    }\n",
        "\n",
        "    # Questions JSON\n",
        "    questions_data = {\n",
        "        \"metadata\": {\n",
        "            \"generated_at\": datetime.now().isoformat(),\n",
        "            \"total_questions\": len(questions),\n",
        "            \"book_title\": \"Project Management Professional Guide\",\n",
        "            \"tool_used\": \"GPT-4\"\n",
        "        },\n",
        "        \"questions\": questions\n",
        "    }\n",
        "\n",
        "    return topics_data, questions_data\n",
        "\n",
        "def save_to_json(data, filename):\n",
        "    \"\"\"Save data to a JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(data, f, indent=4)\n",
        "    except Exception as e:\n",
        "        print(f\"Error while saving to {filename}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_path = \"/content/Project.pdf\"\n",
        "    # Step 1: Extract text with page numbers from the PDF\n",
        "    text_segments = extract_text_with_page_numbers(pdf_path)\n",
        "\n",
        "    # Step 2: Extract up to 10 keywords\n",
        "    keywords = extract_keywords(text_segments, limit=10)\n",
        "\n",
        "    # Step 3: Generate questions for each keyword\n",
        "    questions = []\n",
        "    for keyword in keywords:\n",
        "        for segment in text_segments[:3]:  # Use the first few pages as context\n",
        "            question_data = generate_question_from_keyword(keyword, segment)\n",
        "            if question_data:\n",
        "                question_data[\"topic\"] = keyword  # Add keyword as the topic\n",
        "                questions.append(question_data)\n",
        "\n",
        "    # Step 4: Format output and save to JSON\n",
        "    topics_data, questions_data = format_output(keywords, questions)\n",
        "    save_to_json(topics_data, \"keywords.json\")\n",
        "    save_to_json(questions_data, \"questions.json\")\n",
        "\n",
        "    print(\"Keyword-based question generation completed with page numbers and saved to JSON!\")\n"
      ]
    }
  ]
}